\addcontentsline{toc}{chapter}{\uppercase{Abstract}}
\begin{center}
\large{\textbf{\uppercase{Abstract}}}\linebreak

\vskip .5cm

%\large{\textbf{\uppercase{Speaker Localization (SpeaCal) Subsystem for RESTU's an Engine for Synthetic Thespian Units (RESTU)}}}\linebreak

\large{\textbf{\uppercase{The Design and Implementation of \textit{RESTU's an Engine for Synthetic Thespian Units} (RESTU): Speaker Localization Subsystem (SpeaCal)}}}

\vskip .5cm

\normalsize{\textbf{By}}\linebreak
\large{\textbf{Aditya Arie Nugraha\linebreak
NIM: 23209346\linebreak
\uppercase{Electrical Engineering Master Program}}}\linebreak
\end{center}

\singlespacing
As an engine for building an embodied conversational agent (ECA) system, RESTU's an Engine for Synthetic Thespian Units (RESTU) required at least one subsystem that can provides user (speaker) position information. Such information can be used to enhance the interaction between virtual agent and user, for example to make eye contact between them. The user position can be estimated using the sound signals captured by the microphones or the images captured by the cameras.

This research aimed to design, implement, and test the speaker localization subsystem (named SpeaCal), then integrate the subsystem with RESTU. To estimate the user position, SpeaCal tried to utilize Time Difference Of Arrival (TDOA) and Peak-to-Peak Amplitude Ratio (PtPAR) parameters as the Artificial Neural Network (ANN) input.

The hardwares used to implement SpeaCal were a computer or laptop, USB sound cards which had single input channel and only support 24 KHz sample rate, and microphones. SpeaCal used a microphone array that consisted of four microphones.

From the ANN data acquisition process, it is known that the TDOA value generated by SpeaCal could not be used as ANN input because its consistency is very poor and likely to be invalid. This was caused by the time-constraint which was essential for TDOA calculation could not be met. Therefore, SpeaCal only used PtPAR parameter to estimate user position.

A training data that consisted of 240 data and a testing data that consisted of 60 data are used in ANN training process. Both training and testing data were constructed using two data sets. Then, the resulting ANN is tested using three other data sets which consisted of 200 data in total. The best ANN obtained from training processes had 3 layers with 16 hidden neurons. The mean squared error (MSE) of its training process reached 0.000149964, while the testing reached 0.005309. The MSE of three other testing processes reached 0.139543, 0.210295, and 0.464500.

Then, the ANN was used in the testing of SpeaCal which had been integrated with RESTU. The testing showed that SpeaCal could provide user position estimation for RESTU in real-time, although the estimated user positions were often still inaccurate.

\vskip .5cm
\hangpara{5.25em}{1}
Keywords: speaker localization, time difference of arrival, peak-to-peak amplitude ratio, artificial neural network, microphone array

\onehalfspacing